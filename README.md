
<img align="right" width="200" height="200" src="https://avatars.githubusercontent.com/u/115706761?s=400&u=7c6cae892816e172b0b7eef99f2d32adb948c6ad&v=4">

## Acoustic Monitoring of Bat sounds

The study of the production, transmission, and classification of animal sounds in nature is called bioacoustics. Animal vocalisations and natural soundscapes are fascinating objects of study, and contain valuable evidence about animal behaviours, populations and ecosystems.

Understanding bat populations and behavior is crucial for their conservation, but these nocturnal creatures are difficult to study directly. Their speed, nighttime activity, and preferred habitats make traditional observation methods impractical. Nonetheless, bats use ultrasonic sounds for navigation, making passive acoustic monitoring powerful tool for bat research.
 
In summary, classification of the acoustic repertoires of bats into sound types is a useful tool for taxonomic studies, behavioral studies, and for documenting the occurrence of bats.

## Scalogram-Based Deep Learning Approach 

In the exciting new world of Artificial Intelligence (AI), deep learing-based computer vision (CV)   lets computers "see" and classify images. But what if could applied CV to "hear"  and classify sounds? 

Acoustic classification with CV marries the two domains by applying the principles of visual understanding to audio data. It leverages deep learning techniques to "see" sound, just as it would with images. This innovation has opened doors to a plethora of applications that were once out of reach.

Imagine trying to identify a bat species just by listening to its sounds. That's what Acoustic Scene Classification (ASC) is all about! For years, scientists relied on features like pitch and loudness, calculated by hand, to classify sounds. But recently, a new approach has emerged. Deep learning, a type of artificial intelligence, can automatically analyze images of sound – spectrograms – to understand the environment. This is especially helpful when there are many different environments to identify, making ASC much more powerful!

https://huggingface.co/blog/Andyrasika/voice-with-vision


![image](https://github.com/HR-DATA-FABRIC/CLASSIFYING_ANIMAL_SOUNDS-with-MACHINE_LEARNING/assets/684692/f48cc7d4-8497-4610-93ef-a18c219f5546)



![image](https://github.com/HR-DATA-FABRIC/CLASSIFYING_ANIMAL_SOUNDS-with-MACHINE_LEARNING/assets/684692/3273ff1c-bbec-49f6-a89d-157202d18773)

![image](https://github.com/HR-DATA-FABRIC/CLASSIFYING_ANIMAL_SOUNDS-with-MACHINE_LEARNING/assets/684692/e2ad7597-484b-40d3-b02e-15ca445b0a9b)

Spectrograms and oscillograms of typical echolocation calls emitted during search flight by 18
species of New World molossid bats.



![image](https://github.com/HR-DATA-FABRIC/CLASSIFYING_ANIMAL_SOUNDS-with-MACHINE_LEARNING/assets/684692/2bd3776f-9e19-4da3-82bb-32f77fb7e187)

